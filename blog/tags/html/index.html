<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Ciaran McNulty]]></title>
    <link href="/blog/tags/html" rel="self"/>
    <link href="/"/>
    <updated>2016-02-13T09:34:57+00:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Always declare a media type in your CSS links]]></title>
            <link href="/always-declare-a-media-type-in-your-css-links"/>
            <updated>2010-07-08T00:00:00+00:00</updated>
            <id>/always-declare-a-media-type-in-your-css-links</id>
            <content type="html"><![CDATA[<p>An odd one today at work, a site had the following:</p>

<code><pre>
&lt;link rel="stylesheet" href="styles.css" /&gt;
&lt;link rel="stylesheet" href="print.css" media="print" /&gt;
</pre></code>

<p>What was puzzling was that when you printed the page from Firefox, none of the styles from <tt>styles.css</tt> were being applied. I for one had assumed that it would be inherited.</p>

<p>It turns out that it's not clear what the default media value for the <tt>link</tt> element is.  <a href="http://www.w3.org/TR/REC-html40/present/styles.html#adef-media">The HTML4 spec</a> says:</p>

<blockquote>
This attribute specifies the intended destination medium for style information. It may be a single media descriptor or a comma-separated list. The default value for this attribute is "screen".
</blockquote>

<p>Pretty clear-cut, although maybe not what I expected - looks like if the <tt>media</tt> attribute is missing the styles only apply to screens. But hang on, look what <a href="http://dev.w3.org/html5/spec/Overview.html#attr-link-media">the HTML5 spec</a> says:</p>

<blockquote>
The default, if the media attribute is omitted, is "all", meaning that by default links apply to all media.
</blockquote>

<p>That's a more sensible default of course, but it's unusual to see the HTML5 spec completely change behaviour like this. The fact it has changed indicates that browsers are (currently) being inconsistent about which value to default to.</p>

<p>For now, it seems sensible to <em>always</em> declare a media value in your <tt>link</tt>s, and not make assumptions like we did!</p>

]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[XHTML not dead, despite reports]]></title>
            <link href="/xhtml-not-dead-despite-reports"/>
            <updated>2009-07-20T00:00:00+00:00</updated>
            <id>/xhtml-not-dead-despite-reports</id>
            <content type="html"><![CDATA[<p>With the W3C's recent <a href="http://www.w3.org/News/2009#item119">announcement that work on XHTML 2.0 is not being continued</a>, it would be tempting to think that the HTML vs XHTML war has been 'won', and not by the side a lot of people wanted.</p>

<p>However, that's a misconception.  XHTML is alive and well as part of <a href="http://www.w3.org/TR/html5/">HTML5</a>, on more or less equal terms with 'plain' HTML.  It's just not going to be replacing 'tag soup' any time soon unless people start using it!</p>

<p>I'll be taking a look at the options authors have for producing XHTML markup, but lets first look at why someone might want to use XML.</p>

<h4>Pros and cons of XHTML</h4>

<p>Pros:</p>

<ul>
<li>Parsing - XHTML pages can be parsed using standard XML toolkits.</li>
<li>Transforms - pages can have XSL transforms applied to them.</li>
<li>Embedded content - pages can have other XML namespaces embedded into them.</li>
<li>Unambiguous - the author doesn't have to remember whether a tag needs closing or not, or whether the tag should be upper or lowercase.  This also taps into the general developer's 'coolness' gene.</li>
<li>XML is 'cool'.</li>
</ul>

<p>Cons:</p>

<ul>
<li>Brittleness - it's a lot easier to make a mistake that renders the page invalid XHTML.</li>
<li>Deprecated JS - you can't use some constructs like document.write().</li>
<li>No iFrames - these aren't supported in XHTML strict.</li>
<li>MIME type - there is confusion about which type XHTML should be served as (see next section).</li>
</ul>

<p>To be honest, it is worth considering whether those pros are worth it for you.  There are plenty of people who think you should just use HTML 4.01 and not worry about XML.</p>

<h4>Option 1: Use XHTML 1.1 and serve it as text/html</h4>

<p>Just because XHTML 2.0 has gone away, it doesn't mean you have to jump on board XHTML 5 - browsers will continue supporting XHTML 1.1 for decades to come.</p>

<p>There are a few caveats to consider when using XHTML but serving it as HTML. The <a href="http://www.w3.org/TR/xhtml-media-types/#text-html">W3C XHTML Media Types recommendation</a> states:</p>

<blockquote>
"In general, this media type is NOT suitable for XHTML except when the XHTML is conforms to the guidelines in Appendix A. In particular, 'text/html' is NOT suitable for XHTML Family document types that add elements and attributes from foreign namespaces, such as XHTML+MathML [...] XHTML documents served as 'text/html' will not be processed as XML"
</blockquote>

<p>In short, even if your DOCTYPE says your document is XHTML 1.1 Strict, your browser will not believe you and will basically parse it as HTML.  There is good reason for this -however: surveys suggest that less than 40% of documents online validate against the doctype they declare.</p>
 
<p>Anecdotally, the Microformats community has developed a number of proxy services that take HTML pages as input and transform them to other document types, and nearly all of them have run into the problem of supposedly-XHTML documents causing errors when fed into XSL engines.  Most now run content through Tidy before processing.</p>

<p>This option means:</p>

<ul>
<li>Your pages have to be valid HTML 4.01 anyway, by using the Appendix A compatibility guidelines.</li>
<li>You can't use any of the XML features like namespaces.</li>
<li>Consumers are advised not to trust that it's XML anyway, so browser will render it the same as HTML 4.01.</li>
<li>Consequently, this option is best thought of as a subset of HTML 4.01 where the document just happens to also be valid XML.</li>
</ul>

<h4>Option 2: Use XHTML 1.1 served as application/xhtml+xml</h4>

<p>The <a href="http://www.w3.org/TR/xhtml-media-types/#text-html">same W3C document quoted above</a> says:</p>

<blockquote>
"Family documents. 'application/xhtml+xml' should be used for serving XHTML documents to XHTML user agents (agents that explicitly indicate they support this media type)."
</blockquote>

<p>In short, even if you're serving documents as text/html to some clients, you should use application/xhtml+xml for those that say they can support it, like most modern browsers except IE.  Very few sites actually do this.</p>

<p>The reason is that when served as application/xhtml+xml, browsers actually trust that your document is going to be XML and throw valiation errors or break when it's not.  Why is that bad? Well, it turns out it's actually pretty hard to guarantee this, even at the server side.</p>

<p>Developers are reasonably conversant in XML syntax, but does that apply to everyone that gets to generate content on your site?  Maybe there's a junior front-end developer who knows how to bash HTML in Dreamweaver, maybe users can post content onto the site themselves, or maybe your super-genius senior developers will occasionally make a typo.</p>

<p>Essentially the upshot of this option is:</p>
<ul>
<li>If you do this for some clients, you still have to do Option 1 for other users, which means you either have to do everything twice, or you have to duplicate your work.</li>
<li>You have to do a lot more work ensuring that your markup is valid XML at the server side.</li>
<li>You do get to use XML-specific features, as long as you don't mind not serving your content to some users.</li>
</ul>

<h4>Option 3: Use XHTML5</h4>

<p>At this point in the post, you're probably thinking that XHTML is a bit of a mess, and might be hoping that I'm going to say that HTML5 solves all the problems.  Sadly, that's not the case.</p>

<p>HTML5 does however clean the issues up somewhat. </p> 

<p>For a start, unlike HTML 4.01 vs XHTML 1.1, the XML element of HTML5 is in the core of the specification.  The HTML5 spec (or proposed spec, I should say) defines the elements and attributes in terms of a parsed DOM, and then explains how they should be serialised into XML and 'HTML' forms.

<p>The spec also goes to great lengths to specify a parsing and error-handling model for the HTML serialisations, so that browsers can know the 'right' way to parse seemingly-malformed content like &lt;p&gt;&lt;b&gt;&lt;/p&gt;&lt;/b&gt;> and get a consistent result.  This may seem like a waste of time in a world where XML exists, but in reality with so many hand-coded sites out there, it's a good idea to have a consistent set of rules about how to handle bad markup.</p>

<p>One other way that HTML5 clarifies the split between HTML and XHTML is that the two document types share a consistent DOCTYPE:</p>

<p>&lt;!DOCTYPE html&gt;</p>

<p>Think about the current generation's situation:</p>
<ul>
<li>Documents served as text/html with the HTML 4 doctype are HTML</li>
<li>Documents served as text/html with the XHTML 1.1 doctype are HTML and valid XHTML</li>
<li>Documents served as application/xhtml+xml and the XHTML 1.1 doctype are XHTML</li>
</ul>

<p>By having a single DOCTYPE, HTML5 avoids the awkward middle situation:</p>
<ul>
<li>Documents served as text/html with the HTML5 doctype are HTML</li>
<li>Documents served as application/xhtml+xml with the HTML docytpe are XHTML</li>
</ul>

<p>This option seems like a good one going forwards, as HTML5 elements become more and more supported by browsers:</p>
<ul>
<li>Authors who can guarantee their pages are valid XML can serve them as XHTML to supporting browsers.</li>
<li>Authors who think their pages are probably XML can serve them as text/html and if any mistakes sneak in, it won't matter too much.  The HTML parsing engine in HTML5 should render their documents as intended anyway.</li>
<li>Authors who don't want to worry about XML can write their pages as HTML and continue not to care about whether they're parsable by XML toolkits, as they know that the content-type and DOCTYPE they're using offer no such guarantees to consumers.</li>
</ul>

<h4>The future</h4>

<p>My own feeling is that the XHTML 1.1 specification didn't bring much to the table for browser manufacturers.  It defined a new MIME type for them to recognise, and started asking them to validate pages as XML in some instances, but didn't actually add much in terms of useful features - browsers already had an HTML rendering engine after all, so it's not as if XHTML made anything easier for them.</p>

<p>Also from the development side, XHTML was implemented on sites for a few different motivations: a sense of neatness, the wish to keep up with the latest thing, but there was rarely a business case for its implementation - very few sites rely on their output being parsable as XML.</p>

<p>Hopefully by having XML at the core of the new specification, XHTML will be more and more embraced.  When user-agents are upgraded to parse the new markup, programming teams will also feel the need to implement the XML parser as well as the HTML parser.  Similarly, when sites are redesigned to be HTML5-compatible, hopefully in a lot of cases XML-compatibility will be included in that work.</p>

<p>However, in another sense hopefully HTML5's strong specification of how HTML should be parsed will enable browser manufacturers to further standardise how they treat 'tag soup', and maybe those amateur hand-coders out there will find that their non-validating badly-written code is at least achieving the goal of working roughly the same no matter what browser looks at it.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Make all your sites work in IE8 with one fell swoop]]></title>
            <link href="/make-all-your-sites-work-in-ie8-with-one-fell-swoop"/>
            <updated>2009-04-17T00:00:00+00:00</updated>
            <id>/make-all-your-sites-work-in-ie8-with-one-fell-swoop</id>
            <content type="html"><![CDATA[<p>At work we have around 100 sites hosted for clients, some of which might not have been updated in a few years (I should point out these are sites we develop, so there's no chance a client's going to edit the site themselves).  <a href="http://blogs.msdn.com/ie/archive/2009/04/10/prepare-for-automatic-update-distribution-of-ie8.aspx">IE8 is going to be rolled out to Windows users with Automatic Updates enabled</a> as of next week, so there's a small worry about auditing these sites in time.</p>

<p>When IE7 came out we had to spend the time going through each of them manually and checking everything was fine.  This time around,<a href="http://msdn.microsoft.com/en-us/library/cc288325(VS.85).aspx"> although IE8 has a new rendering model, it's possible for the browser to render pages as if it was IE7</a>.  In general this has been hugely controversial, but for people in our situation it's pretty handy.</p>

<p>The easiest solution to having sites that may not work in the IE8 renderer is 'do nothing'.  IE8 has a compatibility button that a user can press that renders the page as if it's IE7.  If enough users press this button, a scary centralised Microsoft database marks you as a naughty site and from then on, IE8 users get to see you in 'compatibility mode' until some time in the future when you fix your site and manage to persuade Microsoft that you should be let back in to the halls of the worthy.</p>

<p>However that sounds like a mess, relies on users jumping through some hoops, and might be a bit tricky to get off the list at a later date.  The strategy we've decided to go for is to explicitly mark all our sites as needing to be rendered in compatibility view, then turn this off for each site in turn as they're audited, at our leisure.</p>

<p>The solution that Microsoft have provided is a new HTTP header, <tt>X-UA-Compatible</tt>.  The semantics of the header have been defined in a way that allows browsers aside from IE to use it but, frankly, I'll be quite upset if they do.</p>

<p>To mark an HTML page as needing to be rendered in IE7 mode, you'd include the following META tag as the first element in its HEAD, telling it to behave as IE7 would.  I've seen some advice online saying the value should be <tt>IE=IE7</tt>, but that will instruct the browser to use IE7 Standards Mode which  isn't ideal. The value I've used here, <tt>IE=EmulateIE7</tt> will tell IE8 to use either IE7 Standards Mode or IE7 Quirks Mode based on the page's <tt>&lt;!DOCTYPE&gt;</tt> using the same algorithm as IE7.</p>

<p><code><pre>&lt;meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7" /&gt;</pre></code></pre>

<p>So there's one solution - go through all the sites and add that tag to the pages. I don't like it though, for a few reasons:</p>

<ol>
<li>It's still fairly labour-intensive to open a load of old sites, work out their templating system and add in the markup.</li>
<li>This tag would be invalid in HTML5 and I don't want to get into bad habits.</li>
<li>It feels like the HTML is being cluttered up.</li>
</ol>

<p>What we've gone with in our setup is to include this instruction as a real HTTP header in our Apache httpd.conf for all sites:</p>

<p><code><pre>Header set X-UA-Compatible: IE=EmulateIE7</pre></code></p>

<p>Now, all of our sites in one go should use the compatibility view.  Then, as we audit them we can add the following to the VirtualHost for each site:</p>

<p><code><pre>Header unset X-UA-Compatible
Header set X-UA-Compatible: IE=IE8 ; optional</pre></code></p>

<p>Once we've tested each site, this will then tell IE8 to render using IE8's engine no matter what the compatibility database says.  You could leave off the header completely for sites, of course, but then you'll end up mired in the compatibility database. You would save the slight overhead of having an IE-specific header, though.</p>]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Rev-canonical should be handled with care]]></title>
            <link href="/rev-canonical-should-be-handled-with-care"/>
            <updated>2009-04-14T00:00:00+00:00</updated>
            <id>/rev-canonical-should-be-handled-with-care</id>
            <content type="html"><![CDATA[<p>A short while back, Google and a bunch of other search engines launched @rel="canonical", a standard for specifying that the current page is a copy of another, more canonical, version hosted elsewhere. <a href="http://ciaranmcnulty.com/blog/2009/02/rel-canonical-should-be-handled-with-care">I blogged about it at the time</a> , and generally approved of the idea but warned against overuse when an HTTP redirect might be more sensible.</p>
  
<p>Recently there's been a large amount of discussion about <a href="http://simonwillison.net/2009/Apr/11/revcanonical/">@rev="canonical"</a> , a proposal that seems to have been floated with the intention of providing <a href=http://revcanonical.appspot.com/ id=zueh title="URL shortening services">URL shortening services</a>. The idea is that my page can 'advertise' some other URLs that it can be found at so that clients can pick a different one to use when referring to it.</p>

<p>In this particular use case I could publish a page at <strong><tt>http://ciaranmcnulty.com/blog/2009-04-14/a-long-blog-post-with-a-complex-url</tt></strong> that had a @rel="canonical" link to <strong><tt>http://ciaran.ws/complex</tt></strong> (I don't really have that domain, don't bother trying it). Applications that wanted a shorter URL for the content (e.g. Twitter clients, SMS gateways) could then use my shorter URL rather than having to get a more obfuscated one from <a href="http://tinyurl.com">TinyURL</a> or somewhere similar.</p>

<p>The number of sites that have already included the markup is staggering in such a short time, and a testament to how a simple markup idea like this can really take off (if only Microformats could gain this kind of uptake!). I've been reading a lot of the commentary that's bouncing around the HTML blogosphere, and thought I'd put my &pound;0.02 in. Frankly, I fail to see the point of all the hooh-hah, for the following reasons:</p>

<h4>@rev is deprecated.</h4>


<p>@rev has been taken out of the proposed HTML5 specification because it's confusing and under-used, so this is probably the worst possible time to start a wide-ranging deployment of a new @rev value. The widespread use will have one of two results, either it'll be completely invalidated when HTML5 is finalised, or the deployment will cause @rev to be put back into the HTML5 spec. Either of these are bad results in my opinion.</p>

<p>The reasons @rev was taken out of the HTML5 proposal are that basically:</p>

<ol>
  <li>Most uses of @rev turned out to be typos of @rel.</li>
  <li>It was pointed that every @rev value could be turned into a @rel just by changing the keyword to indicate a reverse relation, e.g. @rev="parent" and @rel="child" are equivalent.</li>
</ol>

<p>On this basis, a better alternative to @rel="canonical" could be @rel="non-canonical" or something equally trivial - this could also be combined with @rel="alternate".</p>

<h4>Using @rev="canonical" for redirect URLs is wrong</h4>

<p>The idea of @rel="canonical" is to let search engines know that you have duplicate content at other URLs, and which version is the 'correct' one that they should be concentrating on including in their indexes. By that logic, @rev="canonical" should be a list of other URLs at which the same content as the current page exists, but would indicate to a search engine that the current URL is the one that should be used canonically. As an interesting use-case, a search engine could make indexing those URLs low-priority, or just ignore them completely.</p>

<p>However, redirect URLs don't fit in with this usage. They're resources that will redirect to the current one, not resources that contain the same information. The distinction might seem like hair-splitting but I feel it's important that @rel="canonical" is seen as for situations where there are concrete individual pages at differenet URLs.</p>

<p>On a related note, my friend Simon also has some strident opinions about 301 MOVED redirects from URLs that never initially hosted any content that I wish he'd blog about (hint hint!).</p>

<h4>There are better semantics for URL shortening than @rev="canonical"</h4>

<p>OK, so there's probably a use case for saying 'these other URLs have the same content as this page', but nearly all of the discussion has been concentrated on URL shortening.&nbsp; If we're going to use a head LINK to advertise a shorter URL for our content, there has to be a better way than saying 'these other URLs contain the same content' and letting the client check the length of each.</p>

<p>I don't really know what to propose, but something like @rel="shorter-url" or @rel="short-url" or similar would seem to be sensible.&nbsp; Anything's fine as long as it's widespread and gets registered.&nbsp; It'd be nice if someone could knock up an HTML profile for us to use too, but they seem to be on the way out.</p>

<p>Overall, the rev-canonical thing seems to be a fairly simple idea, with a few flaws, that's been overhyped and suddenly implemented everywhere with not much thought going into it.&nbsp; It may well achieve a few things though:</p>

<ol>
  <li>It's got people talking and thinking about @rel values, which is a good thing and might lead to more uptake of technologies like <a href="http://microformats.org/wiki/XFN">XFN</a>.</li>
  <li>It's prompted a lot of discussion about HTML semantics, which is a good thing and could help promote <a href="http://microformats.org/wiki/posh">POSH</a> and <a href="http://microformats.org">Microformats in general</a>.</li>
  <li>It's shown people how easy it can be to roll out a simple semantic HTML change on a large site, which has to be a good thing.</li>
</ol>

<p>I can only hope that that outweighs all the niggles I have with how rev-canonical is used, and frankly it's currently being used in such a narrow use-case that it doesn't really have a huge impact on the way we use the web.</p>

<p>[EDIT: Just as I posted this, <a href=http://annevankesteren.nl/2009/04/rev-canonical id=ry8m title="Anne van Kesteren made the same points as me">Anne van Kesteren made the same points as me</a> , but in about 10% of the words and with none of the waffle.]</p>]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Rel-canonical should be handled with care]]></title>
            <link href="/rel-canonical-should-be-handled-with-care"/>
            <updated>2009-02-16T00:00:00+00:00</updated>
            <id>/rel-canonical-should-be-handled-with-care</id>
            <content type="html"><![CDATA[<p>Something we've been telling clients for years is to not publish the same information in more than one place.  There are many reasons for this from the point of view of web semantics, but the one that makes the clients listen is when we say that Google will penalise their site for it.</p>

<p>As of today Google allow duplicate content as long as you <a href="http://googlewebmastercentral.blogspot.com/2009/02/specify-your-canonical.html">indicate clearly which version is the canonical one</a>.  This entails adding something like the following to the HEAD element in your duplicated page, pointing back to the original:</p>

<code><pre>&lt;link rel="canonical" href="/the-other-page" /&gt;</pre></code>

<p>This approach has been welcomed by many, but I'm fearful that it is duplicating already-existing web semantics as well as encouraging bad habits in web authors.</p>

<h4>Redundancy, or why it's not needed</h4>

<p>HTTP and HTML already have two mechanisms for dealing with URLs that contain duplicate content:</p>

<h5>Permanent redirects</h5> 

<p>If URLs are exactly equivalent, the server can send a <tt>301 Permanent Redirect</tt> header along with the location of the 'real' content.  This is useful in situations where there's no real reason to present different versions of the same page.</p>

<h5>Content-location headers</h5>

<p>HTTP allows the server to return a content-location header to indicate that the content of the current URL is a duplicate of that at another location.  <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html">RFC2616</a> says:</p>
	
<blockquote>
	The Content-Location value is not a replacement for the original requested URI; it is only a statement of the location of the resource corresponding to this particular entity at the time of the request. Future requests MAY specify the Content-Location URI as the request- URI if the desire is to identify the source of that particular entity.
</blockquote>

<p>... which would seem to duplicate the functionality of rel-canonical with an existing HTTP mechanism.  If authors didn't have access to the HTTP headers their server sent, they could embed it directly in their HTML using the META element:</p>

<p><pre>&lt;meta http-equiv="content-location" content="/the-other-page" /&gt;</pre></p>

<p>I'm therefore not sure why Google have chosen to re-invent the wheel in this way, my only guess would be that <a href="http://www.elementary-group-standards.com/html/html5-http-equiv-difference">HTML5 is largely deprecating http-equiv in META tags</a>. My main concern is that rel-canonical will start to be used in places where a permanent redirect would be more appropriate.</p>

<p>Google don't follow any public processes for recommendations like this, presumably they have some internal debates but a lot of the time these things hit the web fully-formed and are powered forwards via Google's massive market share until other search engines support them.  It's a shame that they don't publish proposals before implementation though, as I'm sure a lot of interested groups would have had some strong opinions to share.</p>

<h4>Where rel-canonical should not be used</h4>

<h5>To fix badly configured webservers</h5>

<p>Poorly configured webservers, or rather servers configured without much thought towards URL semantics, appear be the major source of duplicated content.  In that there's no reasoned plan behind these duplications, it's far better that the developer reconfigure the server properly than to start adding in markup to their documents.</p>

<p>Some misconfiguration examples include:</p>

<ul>
	<li><strong>Site available under www.example.com and example.com</strong>.  This is rarely a carefully thought out issue, rather it's often just the server's default behaviour.  The best bet is to pick one subdomain and permanently redirect the other to it.  (It's worth having a look at <a href="http://no-www.org/">no-www.org</a> while you're making the decision).  I can't think of any strong reason for having it available (as in, being served under rather than redirected from) both domains - the site should be served on whatever subdomain you use on your headed notepaper.</li>
	<li><strong>/foo and /foo/ and /foo/index.html all point to the same page</strong>.  Again this is just default behaviour, based on a hierarchical model of websites as folders full of files.  This is easily fixed with a bit of config to redirect all of them to /foo, but it's simple enough for even on a simple site to just standardise on 'missing off index.html in hyperlinks so that the duplicates are never referred to'.</li>
</ul>

<p>In both of these cases, I'd estimate the amount of effort involved in 'fixing' the config to be less than that of each page detecting what URL it's served on and generating an appropriate rel-canonical link.</p>

<h5>To allow chaff in URLs</h5>

<p>I previously wrote about how when a form is submitted the querystring is full of extraneous information, and <a href="http://ciaranmcnulty.com/blog/2008/11/keeping-querystrings-clean-with-zend-framework">how to make the resultant URLs more canonical using redirects</a>.</p>

<p>It would be tempting to do something similar with rel-canonical but <strong>a permanent redirect is appropriate when the two URLs represent the same resource</strong>.  In an example like <tt>/search?size=10&colour=&shape=</tt>, the <em>meaning</em> of both of the requests is 'items that are size 10'.  Therefore it's entirely appropriate to redirect to <tt>/search?size=10</tt>.</p>

<p>Another case worth looking at is when the results of a search are the same as the results of another.  An example might be if the URLs <tt>/search?size=10</tt> and <tt>/search?colour=red</tt> returned the exact same results. This may happen, for instance, if all the red items were only available in size 10.</p>

<p>In this case the two URLs point at clearly different resources ('list of things that are size 10' vs 'list of things that are red'), and the equivalence may change over time.  Therefore it's not something we'd want to do a redirect between - is it an appropriate place for rel-canonical?</p>

<p>Google's definition is a bit quiet on the details of what the exact semantics of rel-canonical are, but more importantly for these kinds of resources it'd be completely impractical to generate a list of which other resources might happen to contain the same list of results at the given time.</p>

<h4>Where rel-canonical should be used</h4>

<p>After all this griping, I can still see some cases where this new semantic might be useful, if we're going to be abandoning the Content-Location HTTP header (or rather, I can think of a few places where content-location would be appropriate that will presumably transfer over).</p>

<p>The commonality between them really is that we don't want to <em>combine</em> the resources, either because we want to slightly vary the way they're presented or because we think that even though they're equivalent at the moment that they might stop being so in the future.</p>

<h5>Presenting resources at different points in a site hierarchy</h5>

<p>A common sort of URL online is: <tt>/red-widgets/widget2000</tt> that contain an identifier for the resource they're looking at as well as some sort of indication of the hierarchy of the site they're in.</p>

<p>Really this sort of slash-separated construction doesn't contain any special meaning it's largely the same as <tt>?category=red-widgets&product=widget2000</tt> except that it contains an implicit hierarchy that hints that you can't have a product identifier without specifying a category.</p>

<p>In a typical application, of course, the page served would contain lots of different contextual stuff such as links to other items in the same category, and maybe some breadcrumbs.  A product may exist in a number of different categories, so we would want to hint that the different URLs were somehow equivalent, without redirecting between them.</p>

<p>Enter rel-canonical, this seems like an entirely appropriate usage to me.  From a resource point of view the page is something like 'widget2000's details in the red-widgets category', which is distinct from 'widget2000's details in the big-widgets category', but their contents are the same and we can hint that using rel-canonical.  Which version is the canonical one I would leave as an exercise to the reader.</p>

<h5>Keeping temporarily-equivalent URLs separate</h5>

<p>This example is from Google's own pages, but is quite a good one.  They quote Wiki type pages, where one wiki entry 'redirects' to another.  The way this is normally handled in Wikis is to not actually do a redirect, but present the same content with a note saying it's a redirect.</p>

<p>Why do this?  Well, the reasoning seems to be that the resources might at some point stop being equivalent, so it's a good idea to keep them separated out.  This would seem to be a reasonable case for a temporary redirect or even a permanent redirect with a short(er) cache header, but in practical terms if the user bookmarks the URL or sends it to a friend, you want them to still have the 'original' URL in their address bar.</p>

<p>This again does seem a reasonable use of rel-canonical, though one I'm less comfortable with.</p>

<h4>Future progress</h4>

<p>I have a few ideas I'd like to see considered for moving this technology forwards:</p>

<ol>
	<li>Adoption of rel-canonical on A elements as well as just HEAD.  A lot of the time (i.e. in the Wiki example) a valid link to the alternate will already exist on the page.  If the @rel could be added on to this rather than having to exist in the head, it would save a bit of effort and keep the markup local to the link.</li>
	<li>Use of this in Microformats, specifically in the field of finding canonical hCards and so on.  There are <a href="http://microformats.org/wiki/hcard-brainstorming-autodiscovery">already efforts to do similar things</a>, but if this semantic becomes widespread it's worth adopting.</li>
	<li>Really, a bit more definition of what this @rel value is trying to indicate in terms of REST semantics.  The wording from Google has so far been fairly focussed on what it means practically for search indexing, but it'd be good to see them look at it from a more academic point of view.</li>
</ol>
]]></content>
        </entry>
    </feed>